{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calisthenics Skills Pose Estimation\n",
    "## Antonio Finocchiaro's progress diary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to track my progression and some thoughts about what I'm working for my thesis in CS followed by the Professor : Antonino Furnari.\n",
    "\n",
    "The goal of this project is to create a sort of pipeline composed by two main sections to predict the various Calisthenics skills from a video and to count the seconds of the holds.\n",
    "I decided to split this process in the first section, about Pose Estimation, made with Openpose model and the second one about the Classifier Neural Network to predict the video.\n",
    "The building of the datasets will be in the first part. They'll be ready for the second one in a few months.\n",
    "\n",
    "# 24/12/2022\n",
    "\n",
    "I worked in the last two days on my Openpose scripts, some codes to automatize some process and etc..\n",
    "Starting from the skills I decided to identify : \n",
    "\n",
    "+ Planche (pl)\n",
    "+ Front lever (fl)\n",
    "+ One Arm Front Lever (oafl)\n",
    "+ Iron Cross (ic)\n",
    "+ Maltese (mal)\n",
    "+ One Arm Handstandm (oahs)\n",
    "+ Back Lever (bl)\n",
    "+ Human Flag (hf)\n",
    "\n",
    "I'll take soon the decision to include the *Victorian* or the *Front Lever touch* due to the similarity between them. \n",
    "The name closed in the bracket is the *id_skill* I'll use on the datasets to identify a skill.\n",
    "\n",
    "# Openpose on Google Colab\n",
    "\n",
    "Recently, I found a way to use Openpose on Colab without install it every time I change runtime or after the refreshing time of 12 hours. \n",
    "I installed Openpose on my google drive acccount (antosw2000@gmail.com) and everytime I open Colab I have to follow these steps : \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I mount drive and copy the openpose directory to the \"home\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%cp -R /content/drive/MyDrive/openPose/openpose /content/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I reinstall the dependencies : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get -qq install -y libatlas-base-dev libprotobuf-dev libleveldb-dev libsnappy-dev libhdf5-serial-dev protobuf-compiler libgflags-dev libgoogle-glog-dev liblmdb-dev opencl-headers ocl-icd-opencl-dev libviennacl-dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I change the permission of the build directory to make the system access the /build/examples/openpose/ folder  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!chmod -R 777 build/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And today morning, I created the following code, to loop on a drive folder containing the video, process every video with some flags and then, put them in their specific folder : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Specifica la cartella contenente i file video\n",
    "\n",
    "import os\n",
    "\n",
    "video_dir=\"/content/drive/MyDrive/datasetRaw/video_to_render/\"\n",
    "\n",
    "# Cicla attraverso tutti i file video nella cartella\n",
    "\n",
    "for video_file in os.listdir(video_dir):\n",
    "    \n",
    "    # Esegui un'operazione su ogni file video (ad esempio, riprodurlo)\n",
    "    #!echo \"$(basename \"$video_file\")\"\n",
    "\n",
    "    video_name = video_file.split(\".\")[0]\n",
    "    \n",
    "    !mkdir -p /content/drive/MyDrive/datasetRaw/json_frames/$video_name    \n",
    "        \n",
    "    video_path = \"/content/drive/MyDrive/datasetRaw/video_to_render/\"+video_file\n",
    "    json_output_path = \"/content/drive/MyDrive/datasetRaw/json_frames/\"+video_name+\"/\"\n",
    "    video_output_path = \"/content/drive/MyDrive/datasetRaw/out_video/\"+video_file\n",
    "\n",
    "    !./build/examples/openpose/openpose.bin \\\n",
    "    -keypoint_scale 3\\\n",
    "    --model_pose BODY_25B \\\n",
    "    --video {video_path} \\\n",
    "    --write_json {json_output_path} --display 0 \\\n",
    "    --number_people_max 1 \\\n",
    "    --write_video {video_output_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to use the following flag :  `-keypoint Ã¬-scale 3` to normalize the (x,y) keypoints couple to from file format to [0,1]. I'm using the model *BODY_25B* to have better accuracy than the COCO one. BODY_25B has 25 keypoints and they are the following : \n",
    "\n",
    "+ 0: 'Nose'\n",
    "+ 1: 'LEye'\n",
    "+ 2: 'REye'\n",
    "+ 3: 'LEar'\n",
    "+ 4: 'REar'\n",
    "+ 5: 'LShoulder' \n",
    "+ 6: 'RShoulder'\n",
    "+ 7: 'LElbow'\n",
    "+ 8: 'RElbow'\n",
    "+ 9: 'LWrist'\n",
    "+ 10: 'RWrist'\n",
    "+ 11: 'LHip'\n",
    "+ 12: 'RHip'\n",
    "+ 13: 'LKnee'\n",
    "+ 14: 'RKnee'\n",
    "+ 15: 'LAnkle'\n",
    "+ 16: 'RAnkle'\n",
    "+ 17: 'UpperNeck'\n",
    "+ 18: 'HeadTop'\n",
    "+ 19: 'LBigToe'\n",
    "+ 20: 'LSmallToe'\n",
    "+ 21: 'LHeel'\n",
    "+ 22: 'RBigToe'\n",
    "+ 23: 'RSmallToe'\n",
    "+ 24: 'RHeel'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tested the code in the previous cell and it worked! I am afraid about the usage that I can do on Colab, but I think to use it carefully and not so often; \n",
    "like rendering 10 videos a time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, having a google drive folder named \"/datasetRaw/json_frames/\" cointaining the folder of each video (with all keypoints inside); i worked with Google Drive API to make a script that download all the folders containing the keypoints in a local folder :  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Google import Create_Service\n",
    "import os\n",
    "import io \n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "import google.auth\n",
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "import shutil\n",
    "\n",
    "CLIENT_SECRET_FILE = 'client_secret_GoogleCloud.json'\n",
    "API_NAME = 'drive'\n",
    "API_VERSION = 'v3'\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "\n",
    "service = Create_Service(CLIENT_SECRET_FILE, API_NAME, API_VERSION, SCOPES)\n",
    "\n",
    "#print(dir(service))\n",
    "\n",
    "parent_folder_id = '1Hu7Oxk82OvpCXmzK-3A2BttWw_us88ow'\n",
    "local_directory = '/home/coloranto/Desktop/tesi/prova_script_keypoints/all_video_keypoints/'\n",
    "\n",
    "\n",
    "# Recursively download the contents of the parent folder\n",
    "def download_folder(folder_id, local_path):\n",
    "    # Query for the list of files and folders in the current folder\n",
    "    query = f\"'{folder_id}' in parents and trashed = false\"\n",
    "    results = service.files().list(q=query, fields=\"nextPageToken, files(id, name, mimeType)\").execute()\n",
    "    items = results.get(\"files\", [])\n",
    "    # Download each file and recursively call this function for each folder\n",
    "    for item in items:\n",
    "        file_id = item['id']\n",
    "        file = service.files().get(fileId=file_id).execute()\n",
    "        file_name = file['name']\n",
    "        if 'folder' in file['mimeType']:\n",
    "            # Recursively call this function for the folder\n",
    "            new_local_path = f'{local_path}/{file_name}'\n",
    "            os.makedirs(new_local_path, exist_ok=True)\n",
    "            download_folder(file_id, new_local_path)\n",
    "        else:\n",
    "            # Download the file\n",
    "            print(f'Downloading file: {local_path}/{file_name}')\n",
    "            request = service.files().get_media(fileId=file_id)\n",
    "            fh = io.BytesIO()\n",
    "            downloader = googleapiclient.http.MediaIoBaseDownload(fh, request)\n",
    "            done = False\n",
    "            while done is False:\n",
    "                status, done = downloader.next_chunk()\n",
    "            fh.seek(0)\n",
    "            # Save the file to the local directory\n",
    "            with open(f'{local_path}/{file_name}', 'wb') as f:\n",
    "                f.write(fh.read())\n",
    "\n",
    "# Create the local directory and start the recursive download\n",
    "os.makedirs(local_directory, exist_ok=True)\n",
    "download_folder(parent_folder_id, local_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google is a .py file I found to resolute the problems with authentication. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from google_auth_oauthlib.flow import Flow, InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaFileUpload, MediaIoBaseDownload\n",
    "from google.auth.transport.requests import Request\n",
    "\n",
    "\n",
    "def Create_Service(client_secret_file, api_name, api_version, *scopes):\n",
    "    print(client_secret_file, api_name, api_version, scopes, sep='-')\n",
    "    CLIENT_SECRET_FILE = client_secret_file\n",
    "    API_SERVICE_NAME = api_name\n",
    "    API_VERSION = api_version\n",
    "    SCOPES = [scope for scope in scopes[0]]\n",
    "    print(SCOPES)\n",
    "\n",
    "    cred = None\n",
    "\n",
    "    pickle_file = f'token_{API_SERVICE_NAME}_{API_VERSION}.pickle'\n",
    "    # print(pickle_file)\n",
    "\n",
    "    if os.path.exists(pickle_file):\n",
    "        with open(pickle_file, 'rb') as token:\n",
    "            cred = pickle.load(token)\n",
    "\n",
    "    if not cred or not cred.valid:\n",
    "        if cred and cred.expired and cred.refresh_token:\n",
    "            cred.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(CLIENT_SECRET_FILE, SCOPES)\n",
    "            cred = flow.run_local_server()\n",
    "\n",
    "        with open(pickle_file, 'wb') as token:\n",
    "            pickle.dump(cred, token)\n",
    "\n",
    "    try:\n",
    "        service = build(API_SERVICE_NAME, API_VERSION, credentials=cred)\n",
    "        print(API_SERVICE_NAME, 'service created successfully')\n",
    "        return service\n",
    "    except Exception as e:\n",
    "        print('Unable to connect.')\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def convert_to_RFC_datetime(year=1900, month=1, day=1, hour=0, minute=0):\n",
    "    dt = datetime.datetime(year, month, day, hour, minute, 0).isoformat() + 'Z'\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tested it and it works! By the way it has a big issue in terms of speed, the download speed is about 1 file/sec. This mean that to download a folder (representing a video) with about 150 json files, he'll need : 150 sec.\n",
    "It has been a nice way to work with Google Drive API but I have to find a better solution in term of speed. \n",
    "\n",
    "Currently doing it manually, will drastically reduce the timing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, between yesterday afternoon and today's one, I realized this code to do the following steps : \n",
    "+ Create a new .csv document and putting in it the first row containing 75 keypoints (x0,y0,c0,x1,y1,c1...) + 3 features : 'nome_video', 'frame_video', 'skill_id'\n",
    "+ Extracting all the keypoints from the folder that I created with the previous script. Inside of them there are all the video keypoints, took by Openpose. \n",
    "+ Putting the .csv document created and extracted from the file name 2 features : \n",
    "    + from : 'flag1_000000000085_keypoints.json' I extracted the 'nome_video' : flag1 and the keypoint : 85\n",
    "    + the last feature I need is the id_skill, used to train later on this dataset. It take this information looping on another dataset I created : \n",
    "\n",
    "\n",
    "![image](./screen%3Adataset.png)\n",
    "\n",
    "I compare the following nome_video and frame_video with all the rows present in this dataset and : \n",
    "if the nome_video is equal to the nome_video of the actual row and the frame_video is contained in the interval [start_skill_frame, end_skill_frame] I extract the skill_id and put it in the .csv I was creating. If the timeframe it's not contained in it, I'll use a generic label to identify the absence of skill : \"null_skill\", it will have 0 value on the final count.\n",
    "\n",
    "This is the script I created : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to extract data froma a local json and save it to a csv file\n",
    "import json\n",
    "import csv\n",
    "import glob\n",
    "import re\n",
    "\n",
    "\n",
    "with open('dataset.csv', 'w') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['NoseX', 'NoseY', 'NoseC',\n",
    "                                'LEyeX', 'LEyeY', 'LEyeC',\n",
    "                                'REyeX', 'REyeY', 'REyeC',\n",
    "                                'LEarX', 'LEarY', 'LEarC',\n",
    "                                'REarX', 'REarY', 'REarC',\n",
    "                                'LShoulderX', 'LShoulderY', 'LShoulderC',\n",
    "                                'RShoulderX', 'RShoulderY', 'RShoulderC',\n",
    "                                'LElbowX', 'LElbowY', 'LElbowC',\n",
    "                                'RElbowX', 'RElbowY', 'RElbowC',\n",
    "                                'LWristX', 'LWristY', 'LWristC',\n",
    "                                'RWristX', 'RWristY', 'RWristC',\n",
    "                                'LHipX', 'LHipY', 'LHipC',\n",
    "                                'RHipX', 'RHipY', 'RHipC',\n",
    "                                'LKneeX', 'LKneeY', 'LKneeC',\n",
    "                                'RKneeX', 'RKneeY', 'RKneeC',\n",
    "                                'LAnkleX', 'LAnkleY', 'LAnkleC',\n",
    "                                'RAnkleX', 'RAnkleY', 'RAnkleC',\n",
    "                                'UpperNeckX', 'UpperNeckY', 'UpperNeckC',\n",
    "                                'HeadTopX', 'HeadTopY', 'HeadTopC',\n",
    "                                'LBigToeX', 'LBigToeY', 'LBigToeC',\n",
    "                                'LSmallToeX', 'LSmallToeY', 'LSmallToeC',\n",
    "                                'LHeelX', 'LHeelY', 'LHeelC',\n",
    "                                'RBigToeX', 'RBigToeY', 'RBigToeC',\n",
    "                                'RSmallToeX', 'RSmallToeY', 'RSmallToeC',\n",
    "                                'RHeelX', 'RHeelY', 'RHeelC',\n",
    "                                'nome_video', 'frame_video', 'skill_id'])\n",
    "    \n",
    "\n",
    "\n",
    "#order alfabetically the folder\n",
    "def natural_sort(l):\n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n",
    "    return sorted(l, key = alphanum_key)\n",
    "\n",
    "#loop on all json file in the folder\n",
    "for i, folder in enumerate(glob.glob(\"./all_video_keypoints/*\")):\n",
    "    \n",
    "    print(\"folder: \", folder)\n",
    "\n",
    "    folder = natural_sort(glob.glob(folder + \"/*\"))\n",
    "    \n",
    "    for file in folder:\n",
    "        \n",
    "        #print(file)\n",
    "\n",
    "        #read the json file\n",
    "        with open(file) as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        #print(file)\n",
    "\n",
    "        if data[\"people\"] == []:\n",
    "            continue\n",
    "\n",
    "        keypoints = data[\"people\"][0][\"pose_keypoints_2d\"]\n",
    "        \n",
    "        #from the name of the file extract the name of the video and the frame\n",
    "        name = file.split(\"/\")[-1]\n",
    "        name = name.split(\"_\")\n",
    "        nome_video = name[0]\n",
    "        #print(\"Name vale : \", name)\n",
    "        #extract the frame number without the 0 at the beginning\n",
    "\n",
    "        #print(\"nome_video vale: \", nome_video)\n",
    "\n",
    "        frame_video = name[1]\n",
    "        frame_video = frame_video.lstrip(\"0\")\n",
    "        if frame_video == \"\":\n",
    "            frame_video = 0\n",
    "\n",
    "        frame_video = int(frame_video)\n",
    "\n",
    "\n",
    "        keypoints.append(nome_video)\n",
    "        keypoints.append(frame_video)\n",
    "        \n",
    "        #print(\"keypoints vale: \", keypoints)\n",
    "        #extract the skill id from dataset.csv comparing the name of the video and the time of the frame\n",
    "\n",
    "        with open('dataset_video.csv', 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            next(reader)\n",
    "            sem = False\n",
    "            for row in reader: \n",
    "                #print(row)\n",
    "\n",
    "\n",
    "                #print(\"Compare \", nome_video, \" with \", row[6])\n",
    "                if nome_video == row[6] and frame_video >= int(row[3]) and frame_video <= int(row[4]):\n",
    "                    #print(\"Sono uguali\")\n",
    "                    keypoints.append(row[6])\n",
    "                    sem = True\n",
    "                    break                \n",
    "            \n",
    "            if sem == False:\n",
    "                keypoints.append(\"null_skill\")\n",
    "\n",
    "            \n",
    "            print(keypoints)\n",
    "        #write the keypoints in the csv file\n",
    "        with open('dataset.csv', 'a') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(keypoints)\n",
    "            \n",
    "#close the csv file\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tested it and it works! This is the dataset.csv I obtain in output : \n",
    "\n",
    "![image2](./dataset_classifier.png)\n",
    "\n",
    "All the rows are the keypoints extracted, all the columns are the feature (78 in total). \n",
    "As we can see, the 'nome_video' column contain the indentifier of the video, 'frame_video' cointain the frame, 'skill_id' represent the **ground truth label**. \n",
    "\n",
    "NB : some frames are missing, this is voluntary, caused to the fact that in the video there are some frames with 0 keypoints; in this case the whole row will have all keypoints value to 0. This is a redundant data!\n",
    "\n",
    "All the features are included between 0 and 1, it's a normalization to uniform the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build the video dataset, I am using a video editor software called **Kdenlive**, it's very easy to use and I render all videos with 960x540px resolution.\n",
    "I find this resolution the best trade off between quality and compression, it's a 16:9 format, between the 1280x720 format and the 720x480 one.\n",
    "All videos has 24 fps, no audio track and a hash value related. \n",
    "\n",
    "I am collecting them in a specific folder : \n",
    "\n",
    "![image3](./image3.png)\n",
    "\n",
    "I know.. they are still only 12 videos but.. I'll increase them gradually over time!\n",
    "My actually goal is to reach about 400-450 total video.\n",
    "\n",
    "I had to resize this cause Openpose has serious difficult to detect the athlete if there are other people in the video and.. in lots of video, not all body part are present. \n",
    "\n",
    "These features, will make my job harder :(\n",
    "\n",
    "I have lots of other info like all the integral video, all the kdenlive projects etc.. I'll find the best organization in few days. \n",
    "All the future updates and thoughts will be present on this notebook. I hope to go on collecting as more video as I can in the future weeks.\n",
    "That's all, Merry Christmas! :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
